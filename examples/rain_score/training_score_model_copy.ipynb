{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# End-To-End Training Example of RNN for rain estimation and detection using PyNNCML\n",
    "This notebook presents an end-to-end example of training a Recurrent Neural Network (RNN) based rain estimation neural network [1] on the openMRG dataset.\n",
    "This tutorial is built using the PyNNCML software package, which provides both tools to simplify the training process of deep learning models for CMLs.\n",
    "We start with obtaining a subset of the OpenMRG dataset and splitting it into training and validation datasets.\n",
    "Afterward, we construct the One Step Network from [1], followed by the training loop.\n",
    "Finally, we analyze the model performance in terms of RMSE and Bias.\n",
    "\n",
    "\n",
    "Notebook structure\n",
    "1. Imports and Installation of PyNNCML\n",
    "2. Hyperparameter settings\n",
    "3. Build Dataset\n",
    "4. Build Neural Network\n",
    "5. Training Loop\n",
    "6. Neural Network Analysis\n",
    "\n",
    "\n",
    "[Run this notebook in colab](https://colab.research.google.com/github/haihabi/PyNNcml/blob/master/examples/training_rnn.ipynb)\n",
    "\n",
    "To run this notebook on Colab using GPU, please do the following:\n",
    "Runtime -> Change runtime type -> Select GPU -> Save\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if os.path.exists('../../pynncml'):\n",
    "    print(\"Import PyNNCML From Code\")\n",
    "    sys.path.append('../../')  # This line is need to import pynncml\n",
    "else:\n",
    "    print(\"Install PyNNCML From pip\")\n",
    "    !pip install pynncml\n",
    "\n",
    "import pynncml as pnc\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "import wandb\n",
    "import random\n",
    "import numpy as np\n",
    "from examples.rain_score.score.score_matching_loss import ScoreMatchingLoss\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "random.seed(0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "window_size = 32\n",
    "lr = 1e-4\n",
    "n_epochs = 3200\n",
    "\n",
    "xy_min = None\n",
    "xy_max = None\n",
    "time_slice = slice(\"2015-06-01\", \"2015-08-14\")  # Time Interval\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Building Training and Validation datasets"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "dataset_base = pnc.datasets.loader_open_mrg_dataset(xy_min=xy_min, xy_max=xy_max, time_slice=time_slice)\n",
    "dataset = pnc.datasets.linkdataset2subsequent(dataset_base)\n",
    "dataset_base.link_set.plot_links()\n",
    "plt.grid()\n",
    "plt.tick_params(left=False, right=False, labelleft=False, labelbottom=False, bottom=False)\n",
    "plt.show()\n",
    "\n",
    "training_dataset, validation_dataset = torch.utils.data.random_split(dataset, [0.8, 0.2])\n",
    "data_loader_all = torch.utils.data.DataLoader(dataset_base, batch_size)\n",
    "data_loader = torch.utils.data.DataLoader(training_dataset, batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(validation_dataset, batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Loss\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "loss_function = ScoreMatchingLoss(torch.ones(1) * 0.1, torch.inf * torch.ones(1)).to(device)\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rain_data = np.asarray(dataset.label)\n",
    "from scipy.stats import expon, gamma\n",
    "\n",
    "res = expon.fit(rain_data)\n",
    "res_gamma = gamma.fit(rain_data - 0.1)\n",
    "print(res, res_gamma, )\n",
    "min_r, max_r, mean_r = np.min(rain_data), np.max(rain_data), np.mean(rain_data)\n",
    "r_array = np.linspace(min_r, max_r)\n",
    "plt.hist(rain_data, density=True, bins=50, label=\"Histogram\")\n",
    "plt.plot(r_array, expon.pdf(r_array, loc=res[0], scale=res[1]), label=\"PDF\")\n",
    "plt.plot(r_array, gamma.pdf(r_array, a=res_gamma[0], loc=0, scale=res_gamma[2]), label=\"PDF Gamma\")\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Rain-Rate[mm/hour]\")\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.show()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Training Loop"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loss Value 2.3202218410157007:   1%|          | 49/4000 [39:23<35:40:04, 32.50s/it] C:\\Users\\haiha\\.conda\\envs\\Research\\lib\\site-packages\\torch\\optim\\lr_scheduler.py:152: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n",
      "Loss Value -504.71315877367283:  17%|█▋        | 698/4000 [3:14:08<13:06:03, 14.28s/it] "
     ]
    }
   ],
   "source": [
    "from examples.rain_score.score.ema import ModelEma\n",
    "from examples.rain_score.conformer.conditional_encoder import RainScoreConformer\n",
    "\n",
    "model = RainScoreConformer(normalization_cfg=pnc.training_helpers.compute_data_normalization(data_loader_all)).to(\n",
    "    device)\n",
    "ema = ModelEma(model)\n",
    "min_value = torch.ones(1).to(device) * 0.1\n",
    "max_value = torch.inf * torch.ones(1).to(device)\n",
    "lr = 1e-6\n",
    "warmup_epochs = 50\n",
    "n_epochs = 4000\n",
    "div_factor = 100\n",
    "wandb.init(project=\"rain_score\")\n",
    "model.update_dropout(0.9)\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=0.0)\n",
    "scheduler_cosin = torch.optim.lr_scheduler.CosineAnnealingLR(opt, n_epochs - warmup_epochs,\n",
    "                                                             eta_min=lr / div_factor)\n",
    "scheduler_warmup = torch.optim.lr_scheduler.LinearLR(opt, 1 / div_factor, 1, total_iters=warmup_epochs)\n",
    "scheduler = torch.optim.lr_scheduler.SequentialLR(opt, [scheduler_warmup, scheduler_cosin], [warmup_epochs])\n",
    "\n",
    "ra = pnc.analysis.ResultsAccumulator()\n",
    "am = pnc.analysis.AverageMetric()\n",
    "model.train()\n",
    "print(\"Start Training\")\n",
    "pbar = tqdm(range(n_epochs), desc='description')\n",
    "pass_loss_sm = None\n",
    "pass_loss_reg = None\n",
    "for epoch in pbar:\n",
    "    am.clear()\n",
    "    model.train()\n",
    "    prob = 0.9 - 0.4 * (epoch + 1) / n_epochs\n",
    "    model.update_dropout(prob)\n",
    "    for rain_rate, data, metadata in data_loader:\n",
    "        opt.zero_grad()\n",
    "\n",
    "        data = data.to(device)\n",
    "        # Random Slice\n",
    "        slice = int(np.random.randint(8, data.shape[1], 1)[0])\n",
    "        data = data[:, -slice:, :]\n",
    "        # Dequantization noise\n",
    "        data = data + torch.rand_like(data) * 0.3 - 0.15  # Dequantization noise\n",
    "        # Baseline Shift\n",
    "        baseline_shift = torch.permute(\n",
    "            torch.nn.functional.avg_pool1d(\n",
    "                torch.permute(torch.randn(data.shape)[:, :, :int(data.shape[-1] / 2)], [0, 2, 1]), 9), [0, 2, 1])\n",
    "        data[:, :, :int(data.shape[-1] / 2)] += baseline_shift\n",
    "        data[:, :, int(data.shape[-1] / 2):] += baseline_shift\n",
    "\n",
    "        metadata = metadata.to(device)\n",
    "        rain_rate = rain_rate.reshape([-1, 1]).float().to(device)\n",
    "        noise = 0\n",
    "        _rr = torch.tensor(rain_rate.data + noise, device=device,\n",
    "                           requires_grad=True)\n",
    "\n",
    "        rain_hat, prior_out = model(data, metadata.to(device), _rr)\n",
    "\n",
    "        rain_hat_sm, rain_hat_reg = rain_hat.clone(), rain_hat.clone()\n",
    "\n",
    "        loss_sm = loss_function(rain_hat_sm, _rr)\n",
    "        loss = loss_sm\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        pass_loss_sm = loss_sm.item()\n",
    "        ema.update(model)\n",
    "\n",
    "        am.add_results(loss=loss.item(), loss_sm=loss_sm.item())\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_avg = am.get_results(\"loss\")\n",
    "    pbar.set_description(f\"Loss Value {loss_avg}\")\n",
    "    res = {\"loss\": am.get_results(\"loss\"),\n",
    "           \"loss_sm\": am.get_results(\"loss_sm\")}\n",
    "    wandb.log(res)\n",
    "    ra.add_results(**res)\n",
    "wandb.finish()"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model_score.pkl\")\n",
    "torch.save(ema.state_dict(), \"model_score_ema.pkl\")"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
